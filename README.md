In this research paper, we introduce an innovative technique for transforming daytime images
into night time counterparts through the application of Generative Adversarial Networks
(GANs). Our approach hinges upon the fundamental recognition that the primary distinction
between day and night images resides in their respective lighting conditions. Leveraging the
capabilities of GANs, our model assimilates the intrinsic characteristics of night images and
orchestrates the transformation of daylight scenes into photorealistic, indistinguishable
nightscapes. GANs can generate night images that are realistic even if the day image has
different lighting conditions than the night image that is being generated. Here we propose the
use of Pix2Pix which is a conditional generative adversarial network (cGAN) that can translate
images from one domain to another. It was first introduced in 2016 by Isola et al., and has since
been used for a variety of tasks, including image colorization, style transfer, and segmentation.
Itâ€™s compromised of a generator with a U-Net-based architecture and a discriminator
represented by a convolutional PatchGAN classifier. One of the applications of this kind of
model is it can help in training of drones in simulated environments by emulating the
environment of Night time with safety of flying in day time.
